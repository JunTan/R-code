
## Step 4: MODELING (Jun Tan, Dennis, Gong Ze)
```{r}
# load data
load("final_data_no_AK.Rda")
```


#### Add missing data of NA from Internet
```{r}
# population missing data get added 
acadia_louisiana = final_data_no_AK$county_name == "acadia " & final_data_no_AK$state_names == "louisiana"
final_data_no_AK[acadia_louisiana, ]$`total population` = 2919
final_data_no_AK[acadia_louisiana, ]$`white population` = 1051
final_data_no_AK[acadia_louisiana, ]$`black population` = 1787

df_used = final_data_no_AK
```


### Cross Validation training for 2016 democrate voting percentage
```{r}
# use final_data_no_AK for predictor base on the voting percent statistic from 12 with population feature. Voting percent statistic from 16 is used for Testing
choose16_dem = c(10, 19:21)
voting16_dem = df_used[choose16_dem]
colnames(voting16_dem)[1] = c('vote_percent')

choose16_gop = c(8,19:21)
voting16_gop = df_used[choose16_gop]
colnames(voting16_gop)[1] = c('vote_percent')

# Only want education statistic
choose12_dem = c(14, 19:21)
voting12_dem = df_used[ , choose12_dem]
colnames(voting12_dem)[1] = c('vote_percent')

choose12_gop = c(12, 19:21)
voting12_gop = df_used[ , choose12_gop]
colnames(voting12_gop)[1] = c('vote_percent')

```

Create a 10-column matrix called `folds` that contains indices for partitioning the `voting12_dem` data frame into 10 folds.

```{r, error=TRUE}
set.seed(24687531)
nTotal = nrow(voting12_dem)
chooseTest = sample(nTotal, size = 457, replace = FALSE)
votingTest_dem = voting12_dem[chooseTest, ]
votingTrain_dem = voting12_dem[ -chooseTest, ]

nTrain = nrow(votingTrain_dem)
# Set the seed so we all get the same results
set.seed(12344321)
permuteIndices = sample(nTrain)

v = 10
folds_dem = matrix(permuteIndices, ncol = v)
```



```{r, error=TRUE}
library(rpart)
cps = c(seq(0.0001, 0.001, by = 0.0001), 
       seq(0.001, 0.01, by = 0.001),
       seq(0.01, 0.1, by = 0.01))
preds_dem = matrix(nrow = nTrain, ncol = length(cps))

for (i in 1:v) {
  trainFold = as.integer(folds_dem[, -i])
  testFold = folds_dem[, i]
  
  for (j in 1:length(cps)) {
    print(c("Enter", i, j))
    tree = rpart(vote_percent ~ .,
            data = votingTrain_dem[trainFold, ], 
            method = "class",
            control = rpart.control(cp = cps[j]))
    preds_dem[testFold,j ] = 
      predict(tree, 
              newdata = votingTrain_dem[testFold, -1],
              type = "class")
  }
}
```


```{r, error = TRUE}
# find the best prediction
cvRates = apply(preds_dem, 2, function(oneSet) {
  dev = as.numeric(votingTrain_dem$vote_percent)
  result = sum (oneSet == dev) / nTrain
  return(result)
  }
)
```


#### Choose the Value for `cp`

From our plot and the following statistics, choose a value for `cp`.  You may not want to choose the `cp` with the smallest error, but choose a slightly larger `cp` that has nearly the same error rate.

```{r, error=TRUE}
library(ggplot2)
ind = which.max(cvRates)

cvRes = data.frame(cps, cvRates)
ggplot(data = cvRes, aes(x = cps, y = cvRates)) +
  geom_line() + 
  labs(x = "Complexity Parameter", y = "Classification Rate")
```


```{r, error=TRUE}
cpChoice = 

finalTree = rpart(vote_percent ~ .,
                  data = votingTrain_dem, 
                  method = "class",
                  control = rpart.control(cp = cpChoice))

# Best model
testPreds = predict(finalTree, 
              newdata = voting16_dem,
              type = "class")

classRate = sum(testPreds == voting16_dem$vote_percent) / 
  nrow(voting16_dem)

classRate
```


### Knn training for 2016 winning party
```{r}
choose16 = c(1,2,8, 10, 19:21, 38, 39)
voting16 = df_used[choose16]
win_gop = voting16$vote_percent_gop16 > voting16$vote_percent_dem16
voting16$win_gop = factor(x = win_gop, levels = c(TRUE, FALSE), labels = c(1, 2))

choose12 = c(1,2,12, 14, 19:21, 38, 39)
voting12 = df_used[ , choose12]
win_gop = voting12$vote_percent_gop12 > voting12$vote_percent_dem12
voting12$win_gop = factor(x = win_gop, levels = c(TRUE, FALSE), labels = c(1, 2))
```

why do we randomize based on the states not on the country?
Bias sample may pick too many from certain region if certain state has more counties, then in the country level, those counties has a higher probability to be picked.


```{r}
# choose the index for training set and test set
set.seed(24687531)
states = unique(voting12$state_names)
votingTrain_gop_ind_1 = c()
votingTrain_gop_ind_2 = c()
votingTest_gop_ind = c()

for(state in states){
  if(!is.na(state)){
    filter = voting12$state_names == state
    selected_df = voting12[filter, ]
    nTotal = nrow(selected_df)
    partition = nTotal/3
    permuteIndices = sample(nTotal)
    if(length(permuteIndices) == 1){
      part3 = permuteIndices[1]
      votingTest_gop_ind = c(votingTest_gop_ind, part3)
    } else if(length(permuteIndices) == 2){
      part1 = permuteIndices[1]
      part2 = permuteIndices[2]
      votingTrain_gop_ind_1 = c(votingTrain_gop_ind_1, part1)
      votingTrain_gop_ind_2 = c(votingTrain_gop_ind_2, part2)
    } else {
      part1 = permuteIndices[1:partition]
      part2 = permuteIndices[(partition+1):(partition+partition)]
      part3 = permuteIndices[(partition+partition+1):(length(permuteIndices))]
      print(state)
      print(c(length(part1), length(part2), length(part3)))
      votingTrain_gop_ind_1 = c(votingTrain_gop_ind_1, part1)
      votingTrain_gop_ind_2 = c(votingTrain_gop_ind_2, part2)
      votingTest_gop_ind = c(votingTest_gop_ind, part3)
    }
  }
}

votingTrain_gop_1 = voting12[votingTrain_gop_ind_1,]
votingTrain_gop_2 = voting12[votingTrain_gop_ind_2,]
votingTest_gop = voting12[votingTest_gop_ind,]
```

#### cross validation
```{r}


```