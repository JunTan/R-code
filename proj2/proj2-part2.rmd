
## Step 4: MODELING (Jun Tan, Dennis, Gong Ze)
```{r}
# load data
load("final_data_no_AK.Rda")
```


#### Add missing data of NA from Internet
```{r}
# population missing data get added 
acadia_louisiana = final_data_no_AK$county_name == "acadia " & final_data_no_AK$state_names == "louisiana"
final_data_no_AK[acadia_louisiana, ]$`total population` = 2919
final_data_no_AK[acadia_louisiana, ]$`white population` = 1051
final_data_no_AK[acadia_louisiana, ]$`black population` = 1787

df_used = final_data_no_AK
```


### Cross Validation training for 2016 democrate voting percentage
```{r}
# use final_data_no_AK for predictor base on the voting percent statistic from 12 with population feature. Voting percent statistic from 16 is used for Testing
choose16_dem = c(10, 19:21)
voting16_dem = df_used[choose16_dem]
colnames(voting16_dem)[1] = c('vote_percent')

choose16_gop = c(8,19:21)
voting16_gop = df_used[choose16_gop]
colnames(voting16_gop)[1] = c('vote_percent')

# Only want education statistic
choose12_dem = c(14, 19:21)
voting12_dem = df_used[ , choose12_dem]
colnames(voting12_dem)[1] = c('vote_percent')

choose12_gop = c(12, 19:21)
voting12_gop = df_used[ , choose12_gop]
colnames(voting12_gop)[1] = c('vote_percent')

```

Create a 10-column matrix called `folds` that contains indices for partitioning the `voting12_dem` data frame into 10 folds.

```{r, error=TRUE}
set.seed(24687531)
nTotal = nrow(voting12_dem)
chooseTest = sample(nTotal, size = 457, replace = FALSE)
votingTest_dem = voting12_dem[chooseTest, ]
votingTrain_dem = voting12_dem[ -chooseTest, ]

nTrain = nrow(votingTrain_dem)
# Set the seed so we all get the same results
set.seed(12344321)
permuteIndices = sample(nTrain)

v = 10
folds_dem = matrix(permuteIndices, ncol = v)
```



```{r, error=TRUE}
library(rpart)
cps = c(seq(0.0001, 0.001, by = 0.0001), 
       seq(0.001, 0.01, by = 0.001),
       seq(0.01, 0.1, by = 0.01))
preds_dem = matrix(nrow = nTrain, ncol = length(cps))

for (i in 1:v) {
  trainFold = as.integer(folds_dem[, -i])
  testFold = folds_dem[, i]
  
  for (j in 1:length(cps)) {
    print(c("Enter", i, j))
    tree = rpart(vote_percent ~ .,
            data = votingTrain_dem[trainFold, ], 
            method = "class",
            control = rpart.control(cp = cps[j]))
    preds_dem[testFold,j ] = 
      predict(tree, 
              newdata = votingTrain_dem[testFold, -1],
              type = "class")
  }
}
```


```{r, error = TRUE}
# find the best prediction
cvRates = apply(preds_dem, 2, function(oneSet) {
  dev = as.numeric(votingTrain_dem$vote_percent)
  result = sum (oneSet == dev) / nTrain
  return(result)
  }
)
```


#### Choose the Value for `cp`

From our plot and the following statistics, choose a value for `cp`.  You may not want to choose the `cp` with the smallest error, but choose a slightly larger `cp` that has nearly the same error rate.

```{r, error=TRUE}
library(ggplot2)
ind = which.max(cvRates)

cvRes = data.frame(cps, cvRates)
ggplot(data = cvRes, aes(x = cps, y = cvRates)) +
  geom_line() + 
  labs(x = "Complexity Parameter", y = "Classification Rate")
```


```{r, error=TRUE}
cpChoice = 

finalTree = rpart(vote_percent ~ .,
                  data = votingTrain_dem, 
                  method = "class",
                  control = rpart.control(cp = cpChoice))

# Best model
testPreds = predict(finalTree, 
              newdata = voting16_dem,
              type = "class")

classRate = sum(testPreds == voting16_dem$vote_percent) / 
  nrow(voting16_dem)

classRate
```


### Knn training for 2016 winning party
```{r}
choose16 = c(1,2,8, 10, 19:21, 38, 39)
voting16 = df_used[choose16]
win_gop = voting16$vote_percent_gop16 > voting16$vote_percent_dem16
voting16$win_gop = factor(x = win_gop, levels = c(TRUE, FALSE), labels = c(1, 2))

choose12 = c(1,2,12, 14, 19:21, 38, 39)
voting12 = df_used[ , choose12]
win_gop = voting12$vote_percent_gop12 > voting12$vote_percent_dem12
voting12$win_gop = factor(x = win_gop, levels = c(TRUE, FALSE), labels = c(1, 2))
```

why do we randomize based on the states not on the country?
Bias sample may pick too many from certain region if certain state has more counties, then in the country level, those counties has a higher probability to be picked.

```{r}
# find the index in df with corresponding "county_name" and "state_names" in selected_df
corresponding_ind = function(selected_df, df, x){
   which((df$county_name==selected_df[x, "county_name"]) &
          (df$state_names==selected_df[x, "state_names"]))[1]
}

```


```{r}
# choose the index for training set and test set
set.seed(24687531)
states = unique(voting12$state_names)
votingTrain_gop_ind_1 = c()
votingTrain_gop_ind_2 = c()
votingTest_gop_ind = c()

for(state in states){
  if(!is.na(state)){
    filter = (!is.na(voting12$state_names) & voting12$state_names == state)
    selected_df = voting12[filter, ]
    nTotal = nrow(selected_df)
    partition = floor(nTotal/3)
    permuteIndices = sample(nTotal)
    if(length(permuteIndices) == 1){
      part3 = permuteIndices[1]
      votingTest_gop_ind = c(votingTest_gop_ind, part3)
    } else if(length(permuteIndices) == 2){
      part1 = permuteIndices[1]
      part2 = permuteIndices[2]
      votingTrain_gop_ind_1 = c(votingTrain_gop_ind_1, part1)
      votingTrain_gop_ind_2 = c(votingTrain_gop_ind_2, part2)
    } else {
      part1 = permuteIndices[1:partition]
      part2 = permuteIndices[(partition+1):(partition+partition)]
      part3 = permuteIndices[(partition+partition+1):(length(permuteIndices))]
      ind1 = unlist(sapply(part1, function(x) corresponding_ind(selected_df, voting12, x)))
      ind2 = unlist(sapply(part2, function(x) corresponding_ind(selected_df, voting12, x)))
      ind3 = unlist(sapply(part3, function(x) corresponding_ind(selected_df, voting12, x)))
      votingTrain_gop_ind_1 = c(votingTrain_gop_ind_1, ind1)
      votingTrain_gop_ind_2 = c(votingTrain_gop_ind_2, ind2)
      votingTest_gop_ind = c(votingTest_gop_ind, ind3)
    }
  }
}

votingTrain_gop_1 = voting12[votingTrain_gop_ind_1,]
votingTrain_gop_2 = voting12[votingTrain_gop_ind_2,]
votingTest_gop = voting12[votingTest_gop_ind,]

voting12[which(is.na(voting12$state_names)),]
```


```{r}
len = c(1:(length(part1)))

for(i in len){
  print(selected_df[part1[i], c("county_name", "state_names")])
  print(voting12[ind1[i], c("county_name", "state_names")])
  print(c("##############################"))
}
```

nrow(votingTest_gop)+nrow(votingTrain_gop_1)+nrow(votingTrain_gop_2) is one less than nrow(voting12) because one row has county_name = "district of columbia" but NA data everywhere, including the voting data. Thus it is removed.

#### cross validation
Set up the 2 fold matrix
```{r}
v = 2
folds = matrix(data = c(votingTrain_gop_ind_1, votingTrain_gop_ind_2), ncol = 2)
```


```{r}
ks = c(seq(1, 5, by = 1))

preds_gop_won = matrix(nrow = nTrain, ncol = length(ks))

```


