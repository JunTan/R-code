---
title: "E-project"
output: html_document
Authors: Jun Tan (SID:26370084), Peirang Xu (SID:25117973), Ze Gong, Qing Guo, WU Peichen
---

### Step 1: DATA WRANGLING

## Merging dataset1 and dataset2: (Peirang Xu)

```{r}
#2016 Voting Data
require(scales)
mydata1 = read.csv("http://www.stat.berkeley.edu/users/nolan/data/voteProject/2016_US_County_Level_Presidential_Results.csv")
mydata1 = as.data.frame(mydata1)
mydata1$state_names = state.name[match(mydata1$state_abbr, state.abb)]
mydata1 =mydata1[,c("state_names","county_name","votes_gop","per_gop","votes_dem","per_dem")]
colnames(mydata1) = c("state_names","county_name","vote_count_gop16","vote_percent_gop16","vote_count_dem16","vote_percent_dem16")
mydata1$vote_percent_dem16 = percent(mydata1$vote_percent_dem16)
mydata1$vote_percent_gop16 = percent(mydata1$vote_percent_gop16)
mydata1 = data.frame(lapply(mydata1, as.character), stringsAsFactors = FALSE)
mydata1$county_name = gsub("County|city|City","", mydata1$county_name)
mydata1$county_name = sub("  ", " ", mydata1$county_name)

#2012 Voting Data
require(XML)
Names = scan("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/stateNames.txt", character())
state_names = Names[c(-1, -3)]
urls = paste("http://www.stat.berkeley.edu/~nolan/data/voteProject/countyVotes2012/", state_names ,".xml", sep = "")

vtDoc <- list(0)
vtRoot <- list(0)
mydata2 = for(i in 1:length(urls)){
  vtDoc[[i]] = xmlParse(urls[i])
  vtRoot[[i]] = xmlRoot(vtDoc[[i]])
}

getData <- function(x) {
  county_name = xpathSApply(x, '//th[@class = "results-county"]/text()',xmlValue)[-1]
  vote_count_gop12 = xpathSApply(x, '//tr[@class = "party-republican race-winner" or @class = "party-republican"]/td[@class ="results-popular"]',xmlValue)
  vote_percent_gop12 = xpathSApply(x, '//tr[@class = "party-republican race-winner" or @class = "party-republican"]/td[@class = "results-percentage"]',xmlValue) 
  vote_count_dem12 = xpathSApply(x, '//tr[@class = "party-democrat" or @class="party-democrat race-winner"]/td[@class ="results-popular"]',xmlValue)
  vote_percent_dem12 = xpathSApply(x, '//tr[@class = "party-democrat" or @class ="party-democrat race-winner"]/td[@class = "results-percentage"]', xmlValue)
  df_col <- data.frame(county_name, vote_count_gop12, vote_percent_gop12, vote_count_dem12, vote_percent_dem12)
  return(df_col)
}

getData2 = lapply(vtRoot, getData)
rows = sapply(getData2, nrow)
state_names = as.character(rep(state.name, rows))
getData2 = do.call(rbind, getData2)
mydata2 = cbind(state_names, getData2)
mydata2 = data.frame(lapply(mydata2, as.character), stringsAsFactors = FALSE)
mydata2$county_name = sub("  ", " ", mydata2$county_name)

#merge two dataframe
data1 = merge(mydata1, mydata2, by = c("state_names", "county_name"), all = TRUE)

```

When I merge the first two data frames, I firstly imported the two datasets of 2016 voting results and 2012 voting results using “read.csv” and “xmlParse”. Then, I kept the county name, state name, vote counts and percentage of Democrats and Republicans in the two data frames. when I merge the first two data frames, I used state name and county name as “by”, and all = TRUE to keep all the rows in the merge in case for further use in the project, so as a result, there are NAs in the merged data frame. In the merge of these two data frames, for example, I found that in the 2016 voting data, the county name of the state Alaska is not specified as is specified in the 2012 voting data, and in the merged data frame, I kept the voting result for Alaska in both 2012 and 2016. Also, the voting data for Arkansas in 2012 is incomplete, but I kept all the rows in 2016 Arkansas voting data.

## Merging data1 and dataset3: (Qing Guo)

```{r}
require("rio")
#2008 Voting Data
#loading data from excel
path = "http://www.stat.berkeley.edu/users/nolan/data/voteProject/" 
file = paste(path, "countyVotes2008.xlsx",sep="")
total =  import(file)#import the first sheet only
states = total$STATE[1:51]
states = gsub("\\*", "", states) #get rid of the * at the end of some state names
mydata3 = list(total) #coerce total into a list
i=2
for (state in states){
  if (state=="D.C."){
    next
  }
  mydata3[[i]]<-import(file,which=state)#the "which" argument can be used to specify the sheet name
  i=i+1
}
#change column names to be algined with those of data1:
  for (i in 2:51){
  colnames(mydata3[[i]]) = c("county_name", "Total Precincts", "Precincts Reporting", "vote_count_dem08", "vote_count_gop08", "other", "NA")
  }
#add percentage to each dataframe
for (i in 2:51){
    mydata3[[i]]$"vote_percent_gop08" = percent(mydata3[[i]]$vote_count_gop08/(sum(mydata3[[i]]$vote_count_dem08, mydata3[[i]]$vote_count_gop08, mydata3[[i]]$other, na.rm = TRUE)))
    mydata3[[i]]$"vote_percent_dem08" = percent(mydata3[[i]]$vote_count_dem08/(sum(mydata3[[i]]$vote_count_dem08, mydata3[[i]]$vote_count_gop08, mydata3[[i]]$other, na.rm = TRUE)))
    
  }
#add the state column for each county
states = states[states!= "D.C."]
for (i in 1:50){
  mydata3[[i+1]]$"state_names" = states[i]
}
#drop Total Precincts, Precincts Reporting, NAs and Other
for (i in 2:51){
  mydata3[[i]] = mydata3[[i]][ , -c(2,3,6,7)]
}
#drop the first total table
mydata3 = mydata3[-1]
#convert from list to a data frame and clean the dataframe
mydata3 = do.call(rbind, lapply(mydata3, data.frame, stringsAsFactors=FALSE))
mydata3 = mydata3[c("state_names", "county_name", "vote_count_gop08", "vote_percent_gop08", "vote_count_dem08", "vote_percent_dem08")]
mydata3$county_name = sub("  ", " ", mydata3$county_name)
#merge two dataframe
data2 = merge(mydata3, data1, by = c("state_names", "county_name"), all = TRUE)

```

For the excel dataset, the alaska voting data and DC voting data are missing in the excel tabs. In order to be algined with the former dataset, I calculated the percentage of democrats and republicans votes in each county. Before the merge, I did some data cleaning so that my 2008 dataset could be adpated to the previous dataset. Since the first table is about the results of each state and I don't need that for our dataframe, I dropped it. During the merge, I used union instead of intersection because at this point we don't know if counties with NA in 2008 have voting data or not for other election years. So I saved those NAs for further use. For instance, the Alaska data is still missing but I choose to keep those county names first even though it gives me back NAs because we want to wait to see the data of other years.

## Merging data2 and dataset4: (WU, Peichen)

```{r}
#reading election results of 2004 into data frame mydata4 
mydata4 = read.table("http://www.stat.berkeley.edu/~nolan/data/voteProject/countyVotes2004.txt", header = TRUE)
mydata4$countyName = as.character(mydata4$countyName)
mydata4$states = gsub(",[a-z ]*", "", mydata4$countyName)
countyName = gsub("[a-z ]*,", "", mydata4$countyName)
countyName = sapply(countyName, function(x) paste(x, " ", sep = ""))
mydata4$countyName = countyName
mydata4 = mydata4[, c(4, 1, 2, 3)]
names(mydata4) = c("state_names", "county_name", "vote_count_gop04", "vote_count_dem04")
sum = mydata4$vote_count_gop04 + mydata4$vote_count_dem04
mydata4$vote_percent_gop04 = percent(mydata4$vote_count_gop04/sum)
mydata4$vote_percent_dem04 = percent(mydata4$vote_count_dem04/sum)

#merging mydata4 with data2
data2$state_names = tolower(data2$state_names)
data2$county_name = tolower(data2$county_name)
data3 = merge(data2, mydata4, by = c("state_names", "county_name"), all = TRUE)

```
After merging the main data frame with the results of 2004, the number of rows increases from 3459 to 3506. But the election results of 2004 only contains 2975 rows, since it only contains the results of counties form 48 states (no data from Alaska and Hawaii). 

## Merging data3 and dataset5: (Jun Tan)

```{r}
# Read in data
B01003 = read.csv(file="http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/B01003.csv",head=TRUE,sep=",")
B01003 = B01003[c(-1,-2)]
```

The first and second column are eliminated because they are not useful in terms of analyzing the correlation betweeen the voting statistic with other census data.

```{r}
DP02 = read.csv(file="http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP02.csv",head=TRUE,sep=",")
DP02 = DP02[c("GEO.display.label", "HC03_VC86", "HC03_VC87", "HC03_VC88", "HC03_VC89", "HC03_VC90", "HC03_VC91", "HC03_VC93", "HC03_VC94")]

DP03 = read.csv(file="http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP03.csv",head=TRUE,sep=",")
DP03 = DP03[c("GEO.display.label", "HC03_VC50", "HC03_VC51", "HC03_VC52", "HC03_VC54", "HC03_VC56", "HC03_VC58", "HC03_VC59", "HC03_VC62")]
```

DP02 gets out the percentage of education level of the population and DP03 gets out the percentage of the occupation in different area of the population.

```{r}
# Function for extract state and county/city from a vector of string. Return values have the first half as county, the bottom half as state
get_county_state = function(county_states) {
  county_states = sapply(county_states, as.character)
  # Get rid of hex character in the county name
  county_states = gsub("[\x01-\x1f\x7f-\xff]", "", county_states) 
  
  county_states = county_states[!is.na(county_states)]
  county_states = strsplit(county_states, ",")
  county_names = sapply(county_states, function(x) x[1])
  county_names = strsplit(county_names, "County")
  county_names = sapply(county_names, function(x) x[1])
  state_names = sapply(county_states, function(x) x[2])
  state_names = sub(" ", "", state_names)
  return(c(county_names, state_names))
}
```


```{r}
# data process for B01003
# Split county names and state names
split_county_states = get_county_state(B01003$GEO.display.label)
len = length(split_county_states)
B01003$county_name = split_county_states[0:(len/2)]
B01003$state_name = split_county_states[(len/2+1):len]

# Extract the data frame, each county-state pair in a row with population stats
col_names =  c("county_name", "state_name", "POPGROUP.display.label", "HD01_VD01", "HD02_VD01")
B01003_total = B01003[B01003$POPGROUP.id == 1, col_names]
B01003_white = B01003[B01003$POPGROUP.id == 2, col_names]
B01003_black = B01003[B01003$POPGROUP.id == 4, col_names]

# Merge different stats
B01003_total_white = merge(x = B01003_total, y = B01003_white, by.x = c("county_name", "state_name"), by.y = c("county_name", "state_name"), all.x = TRUE)

B01003_clean = merge(x = B01003_total_white, y = B01003_black, by.x = c("county_name", "state_name"), by.y = c("county_name", "state_name"), all.x = TRUE)

# Clean the final dataframe
B01003_clean = B01003_clean[c("county_name", "state_name", "HD01_VD01.x", "HD01_VD01.y", "HD02_VD01")]
colnames(B01003_clean) = c("county_name", "state_name", "total population", "white population", "black population")
B01003_clean$`black population` = as.numeric(B01003_clean$`black population`)
```

The last step subset out the needed information to analysis including total population, white population and black population.

```{r}
# Process DP02
# Filter out county_name and state_name
names = c("county_states", "% 9-12th grade no diploma", "% high school grad(eq)", "% some college, no deg", "% AS deg", "% BS", "% MS/PHD", "% of % high school of higher", "% of % BS or higher")
colnames(DP02) = names
split_county_states = get_county_state(DP02$county_states)
len = length(split_county_states)
DP02$county_name = split_county_states[0:(len/2)]
DP02$state_name = split_county_states[(len/2+1):len]

# Clean DP02
DP02_clean = DP02[c("county_name", "state_name", names[2:length(names)])]
```


```{r}
# Process DP03
names = c("county_states", 
          "% Agriculture, forestry, fishing and hunting, and mining", 
          "% Construction", "% Manufacturing", "% Retail trade", "% Information", 
          "% Professional, scientific, and management, and administrative and waste management services", 
          "% Educational services, and health care and social assistance",
          "% Public administration")
colnames(DP03) = names
split_county_states = get_county_state(DP03$county_states)
len = length(split_county_states)
DP03$county_name = split_county_states[0:(len/2)]
DP03$state_name = split_county_states[(len/2+1):len]

# Clean DP03
wanted_coln = names[2:length(names)]
DP03_clean = DP03[c("county_name", "state_name", wanted_coln)]
```

B01003_clean, DP03_clean and DP02_clean are denoted to be dataframes with county_name, state_name and corresponding census information from the dataset.

```{r}
# Merge B01003_clean, DP03_clean and DP02_clean
inter1 = merge(x = B01003_clean, y = DP02_clean, by.x = c("county_name", "state_name"), by.y = c("county_name", "state_name"), all = TRUE)
filter = sapply(inter1$county_name, is.na)
inter1 = inter1[!filter,]
all_3 = merge(x = inter1, y = DP03_clean, by.x = c("county_name", "state_name"), by.y = c("county_name", "state_name"), all = TRUE)
all_3 = all_3[, c(2, 1, 3:21)]
```

The final dataframe "all_3" has all rows from DP03_clean, DP02_clean, and B01003_clean.

```{r}
# Merge my dataframe with the master dataframe
all_3$state_name = tolower(all_3$state_name)
all_3$county_name = tolower(all_3$county_name)
data4 = merge(x = data3, y = all_3, by.x = c("state_names", "county_name"), by.y = c("state_name", "county_name"), all.x = TRUE)
```

data4 includes all information about voting from 2004, 2008, 2012 and 2016 and census data of population, education level and occupation from 2010. We want to keep the rows that has voting statistics because we are analyzing the voting in this project. Those rows with education or occupation information only does not contribute to the analysis of the voting.

## Merging data4 and dataset6: (Gong Ze)

```{r}
#GML data
require(XML)
GMLsource = "http://www.stat.berkeley.edu/users/nolan/data/voteProject/counties.gml"
GMLparse = xmlParse(GMLsource)
GMLroot = xmlRoot(GMLparse)
countyname = xpathSApply(GMLroot, '//county/gml:name',xmlValue)
```


```{r}
state_name = xpathSApply(GMLroot,'//state/gml:name', xmlValue)
state_name_clean = gsub("\n[ ]*", "", state_name)
state_count = sapply(state_name, function(i)
           length(xpathApply(GMLroot, paste0("//state[gml:name='",i,"']/county/gml:name"))))
state_names = rep(state_name_clean, times=state_count)
```


```{r}
latitude = as.numeric(xpathSApply(GMLroot, '//gml:X', xmlValue))/1000000
longitude = as.numeric(xpathSApply(GMLroot, '//gml:Y', xmlValue))/1000000
dataset6 = data.frame(countyname, state_names,latitude,longitude)
dataset6$state_names = tolower(dataset6$state_names)
dataset6$countyname = gsub("county", "", tolower(dataset6$countyname))
dataset6$countyname = gsub("\n[ ]*", "", dataset6$countyname)
big_data = merge(x = data4, y = dataset6, by.x = c("county_name", "state_names"), by.y = c("countyname", "state_names"), all.x = TRUE)
```

## Clean the final dataframe

```{r}
# clean the given dataframe
# remove rows that have any of the column = NA removed by default and return the new dataframe. 
# If selected_name is not NA, then return the dataframe with rows that have any of the colname in the selected_name removed. 
cleanDF = function(df, colname, selected_name = NA){
  filter = !vector(mode = "logical", length = nrow(df))
  if (!is.na(selected_name)) {
    for (name in colname){
      inter_filter = sapply(df[name], function(x) !(x %in% selected_name))
      filter = filter & inter_filter
    }
    df_clean = df[filter,]
  } else {
    for (name in colname){
      inter_filter = sapply(df[name], function(x) !is.na(x))
      filter = filter & inter_filter
    }
    df_clean = df[filter,]
  }
  return(df_clean)
}
```


```{r}
# combine rows with same state name and similar county name because dataset classify county and city differently
comb_similar_row = function(df){
  temp_df = df
  result_df = NA 
  result_df = rbind(result_df, temp_df[1,])
  county_name = temp_df$county_name
  state_names = temp_df$state_names
  for (i in c(2:nrow(temp_df))){
    cName = temp_df[i,]$county_name
    sName = temp_df[i,]$state_names
    filter = (state_names == sName) & grepl(pattern = cName, x = county_name) & !(sName %in% result_df$state_names) & !(cName %in% result_df$county_name)
    p = gsub(pattern = " [A-z]*", " ", c(cName))
    p = gsub(pattern = "  ", " ", p)
    filter2 = grepl(pattern = p[1], x = result_df[result_df$state_names == sName, "county_name"])
    if (!is.na(p) & all(filter2 == FALSE)) {
      result_df = rbind(result_df, temp_df[i,])
    } else if (!is.na(p) & !any(filter2)) {
      similar_row = temp_df[filter, ]
      similar_cNames = similar_row$county_name
      similar_sNames = similar_row$state_names
      for (name in unique(similar_sNames)) {
        filter_df = similar_row[similar_sNames == name, ]
        df1 = filter_df[1,]
        df2 = filter_df[2,]
        df1[which(is.na(df1) & !is.na(df2))] = df2[which(is.na(df1) & !is.na(df2))]
        result_df = rbind(result_df, df1)
      }
    }
  }
  return(result_df[2:nrow(result_df), ])
}
```


```{r}
# clean the big_data by combining the rows with same state_name and similar county/city name
final_data = comb_similar_row(big_data)
```

There are about 200 rows reduction after combining similar rows because some cites were recorded as its city name in some years in some dataset but also recorded as the county it belongs to in some other years in some other datasets. That results in some data are missing in some row but actually those data are in the row paired with the city name or county name. Thus the 'comb_similar_row' merges those missing data together with the corresponding city/county name.

```{r}
# pick rows with state_names are not alaska because alaska does not have sufficient information needed for analysis
final_data_no_AK = cleanDF(final_data, colname = c("state_names"), selected_name = c("alaska"))
save(final_data_no_AK,file="final_data_no_AK.rda")
```

Because most of data from Alaska are missing, including the voting from all different years, Alaska won't contribute a lot to our predictions and plots, it can be removed without causing significant impact.

## References
"http://www.stat.berkeley.edu/users/nolan/data/voteProject/2016_US_County_Level_Presidential_Results.csv"

"http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/stateNames.txt"

"http://www.stat.berkeley.edu/users/nolan/data/voteProject/" 

"http://www.stat.berkeley.edu/~nolan/data/voteProject/countyVotes2004.txt"

"http://www.stat.berkeley.edu/users/nolan/data/voteProject/counties.gml"

"http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/B01003.csv"

"http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP02.csv"

"http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP03.csv"


## Package used
scales
XML
rio

## System info
```{r}
sessionInfo()
```
